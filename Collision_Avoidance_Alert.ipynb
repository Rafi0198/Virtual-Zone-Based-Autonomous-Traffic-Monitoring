{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Necessary Libraries (Database Training Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!nvidia-smi\n",
    "pip install wandb\n",
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Training Configuration (Cloud Environment: Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build from YAML and transfer weights\n",
    "model = YOLO('yolov8x.yaml').load('yolov8x.pt')  \n",
    "\n",
    "# Training The Final Model\n",
    "results = model.train(data=\"/kaggle/input/addbdvss/traffic_update.yaml\",epochs=30, imgsz = 416, batch = 64 ,lr0=0.0001, dropout= 0.15, device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "!yolo task=detect mode=train model=yolov8x.pt data=\"/kaggle/input/addbdvss/traffic_update.yaml\" epochs=30 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free Up Occupied GPU Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Necessary Libraries (Test Part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install ultralytics\n",
    "!pip install cvzone\n",
    "!pip install supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zone Based Collision Avoidance Alert  (Cloud Environment: Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from cvzone import putTextRect\n",
    "import numpy as np\n",
    "from cvzone import cornerRect\n",
    "from cvzone import overlayPNG\n",
    "import supervision as sv\n",
    "\n",
    "# Define the directory to store videos\n",
    "VIDEOS_DIR = os.path.join('.', 'videos')\n",
    "\n",
    "# Specify the input video file and output video file paths\n",
    "video_path = os.path.join(VIDEOS_DIR, r\"/content/drive/MyDrive/YoLo_Thesis/BDV/Test Clips/Test6.mp4\")\n",
    "video_path_out = '{}_out.mp4'.format(video_path)\n",
    "\n",
    "# Open the input video file for reading\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Read the first frame of the video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Get the height, width, and number of channels of the frame\n",
    "H, W, _ = frame.shape\n",
    "\n",
    "# Coordinates of the rectangular portion (ROI)\n",
    "roi_x1, roi_y1, roi_x2, roi_y2 = 0, int(H/7), W, int((3*H)/5)  # Update these coordinates according to your ROI\n",
    "\n",
    "# Create a VideoWriter object to save the output video\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n",
    "\n",
    "# Specify the path of the YOLO model\n",
    "model_path1 = os.path.join('.', r\"/content/drive/MyDrive/YoLo_Thesis/BDTS/runskg2/best(1).pt\")\n",
    "model_path2 = os.path.join('.', r\"/content/drive/MyDrive/YoLo_Thesis/BDV/best.pt\")\n",
    "\n",
    "# Load the YOLO model\n",
    "model1 = YOLO(model_path1)\n",
    "model2 = YOLO(model_path2)\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "trace_annotator = sv.TraceAnnotator()\n",
    "\n",
    "\n",
    "# Set a threshold for object detection confidence\n",
    "threshold = 0.5\n",
    "\n",
    "Ap = np.array([14,15,22,23,24,25,26])\n",
    "Ad = np.array([1,2,11,12,13,16,21])\n",
    "Am= np.array([4,5,6,17,18,19])\n",
    "\n",
    "# Process Graphics Icon\n",
    "\n",
    "imgGraphicsPath = os.path.join('.', r\"/content/drive/MyDrive/YoLo_Thesis/BDV/Test Clips/Capture3.png\")\n",
    "imgGraphics = cv2.imread(imgGraphicsPath, cv2.IMREAD_UNCHANGED)\n",
    "height, width = imgGraphics.shape[:2]\n",
    "imgGraphics = cv2.resize(imgGraphics, (int(height*0.7), int(width*0.7)))\n",
    "\n",
    "\n",
    "\n",
    "# Process each frame of the input video\n",
    "while ret:\n",
    "\n",
    "    # Extract the ROI from the frame\n",
    "    roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "\n",
    "    active_zone = False\n",
    "\n",
    "    #Zone For LOS\n",
    "\n",
    "\n",
    "    # Perform object detection on the ROI using the YOLO model\n",
    "    #results1 = model1(roi)[0]\n",
    "    results2 = model2(frame)[0]\n",
    "\n",
    "    # Iterate through the detected objects in the ROI\n",
    "    # for result1 in results1.boxes.data.tolist():\n",
    "    #     x1, y1, x2, y2, score, class_id = result1\n",
    "\n",
    "    #     # Check if the detection confidence is above the threshold\n",
    "    #     if score > threshold:\n",
    "    #         # Adjust the coordinates to the original frame\n",
    "    #         x1 += roi_x1\n",
    "    #         x2 += roi_x1\n",
    "    #         y1 += roi_y1\n",
    "    #         y2 += roi_y1\n",
    "\n",
    "    #         class_name = results1.names[int(class_id)].upper()\n",
    "    #         confidence = round(score * 100, 2)\n",
    "\n",
    "    #         #cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 4)\n",
    "    #         cornerRect(frame, (int(x1), int(y1), int(x2)-int(x1), int(y2)-int(y1)), l=6, rt=4, t=3, colorR=(0, 0, 255), colorC=(0, 255, 0))\n",
    "    #         #cv2.putText(frame, f'{class_name} {confidence}%', (int(x1), int(y1 - 10)),\n",
    "    #                     #cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    #         putTextRect(frame, f'{class_name} {confidence}%', [int(x1), int(y1) -15],\n",
    "    #                     scale=1.5, thickness=2,colorR=(0,0,255), offset=7)\n",
    "\n",
    "    #        #putTextRect(frame, f'{class_name} {confidence}%', [int(x1), int(y1) - 20],\n",
    "    #                     #scale=1.5, thickness=2)\n",
    "\n",
    "    #         if class_id in Ap:\n",
    "\n",
    "    #          putTextRect(frame, f'{\"PROHIBITORY\"}', [int(x1) + 8, int(y2) +30],\n",
    "    #                     scale=1.5, thickness=2,colorR=(0,0,255))\n",
    "\n",
    "\n",
    "    #         elif class_id in Ad:\n",
    "\n",
    "    #          putTextRect(frame, f'{\"DANGER\"}', [int(x1) + 8, int(y2) +30],\n",
    "    #                     scale=1.5, thickness=2,colorR=(0,0,255))\n",
    "\n",
    "\n",
    "    #         elif class_id in Am:\n",
    "\n",
    "    #          putTextRect(frame, f'{\"MANDATORY\"}', [int(x1) + 8, int(y2) +30],\n",
    "    #                     scale=1.5, thickness=2,colorR=(255,0,0))\n",
    "\n",
    "\n",
    "    #         else:\n",
    "\n",
    "    #          putTextRect(frame, f'{\"OTHERS\"}', [int(x1) + 8, int(y2) +30],\n",
    "    #                     scale=1.5, thickness=2,colorR=(0,128,255))\n",
    "\n",
    "    #         # Check if the current bounding box is within the specified ROI\n",
    "    #         if ((x1 >= roi_x1) and (x2 <= roi_x2) and (y1 >= roi_y1) and (y2 <= roi_y2)):\n",
    "    #                 active_zone = True\n",
    "\n",
    "    # Check the condition here based on the active_zone variable\n",
    "\n",
    "\n",
    "\n",
    "    for result2 in results2.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result2\n",
    "\n",
    "        x1=int(x1)\n",
    "        x2=int(x2)\n",
    "        y1=int(y1)\n",
    "        y2=int(y2)\n",
    "        w=x2-x1\n",
    "        cv2.rectangle(frame,  (int((W/2)-0.2*W), 0), (int((W/2)+0.2*W), H) , (0, 255, 0), 2)\n",
    "\n",
    "        if score > threshold:\n",
    "\n",
    "            class_name = results2.names[int(class_id)].upper()\n",
    "            #confidence = round(score * 100, 2)\n",
    "            #cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 4)\n",
    "            #cornerRect(frame, (int(x1), int(y1), int(x2)-int(x1), int(y2)-int(y1)), l=8, rt=2, t=5, colorR=(153, 51, 255), colorC=(0, 255, 0))\n",
    "            #cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        #cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "            # putTextRect(frame, f'{class_name} {confidence}%', [int(x1), int(y1) -10],\n",
    "            #                     scale=1, thickness=2, colorR=(153, 51, 255), offset=5)\n",
    "\n",
    "            center = ((x1+x2)/2 , (y1+y2)/2)\n",
    "\n",
    "            ratio = (w/W)\n",
    "            cv2.putText(frame, f'{ratio:.2f}', (int(center[0]), int(center[1])-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            if ratio >0.29:\n",
    "\n",
    "              if ((x1 >= int((W/2)-0.2*W)) or (x2 <= int((W/2)+0.2*W)) or (y1 >= 0) and (y2 <= H)):\n",
    "                cv2.putText(frame, \"CAUTION!\", (int(center[0]), int(center[1])+20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "                overlayPNG(frame, imgGraphics, (int(center[0]), int(y1-20)))\n",
    "\n",
    "            p2x, p2y = 667, 483\n",
    "            width = 60 #100\n",
    "\n",
    "            p1 = 506, 720\n",
    "            p2 = p2x, p2y\n",
    "            p3 = p2x+width , p2[1]\n",
    "            center = (p2[0]+p3[0])/2 , p2x\n",
    "            p4 = p1[0] + (center[0]-p1[0])*2 , 720\n",
    "\n",
    "            # Convert points to a numpy array\n",
    "            pts = np.array([p1, p2, p3, p4], np.int32)\n",
    "            pts = pts.reshape((-1, 1, 2))\n",
    "\n",
    "            # Draw the polygon\n",
    "            cv2.polylines(frame, [pts], isClosed=True, color=(0, 0, 255), thickness=4)\n",
    "            #cv2.imshow(\"Image\", img)\n",
    "\n",
    "            zone1pts1 = 641 , 522\n",
    "            zone1pts2 = (zone1pts1[0] + int(center[0]-zone1pts1[0])*2) , zone1pts1[1]\n",
    "            cv2.line(frame, pt1=zone1pts1, pt2=zone1pts2, color=(255,0,0), thickness=4)\n",
    "\n",
    "            ptsZone1 = np.array([zone1pts1, p2, p3, zone1pts2], np.int32)\n",
    "            ptsZone1 = ptsZone1.reshape((-1, 1, 2))\n",
    "\n",
    "            zone2pts1 = 593 , 592\n",
    "            zone2pts2 = zone2pts1[0] + int(center[0]-zone2pts1[0])*2 , zone2pts1[1]\n",
    "            cv2.line(frame, pt1=zone2pts1, pt2=zone2pts2, color=(255,0,0), thickness=4)\n",
    "\n",
    "            ptsZone2 = np.array([zone2pts1, zone1pts1, zone1pts2, zone2pts2], np.int32)\n",
    "            ptsZone2 = ptsZone2.reshape((-1, 1, 2))\n",
    "\n",
    "            ptsZone3 = np.array([p1, zone2pts1, zone2pts2, p4], np.int32)\n",
    "            ptsZone3 = ptsZone3.reshape((-1, 1, 2))\n",
    "\n",
    "\n",
    "\n",
    "            # Set the mouse callback function\n",
    "            #cv2.setMouseCallback('Image', get_coordinates)\n",
    "\n",
    "            # Create a mask image the same size as the original image\n",
    "            mask = np.zeros_like(frame)\n",
    "\n",
    "            # Fill the polygon on the mask with a color (e.g., red with some transparency)\n",
    "            cv2.fillPoly(mask, [ptsZone1], (0, 255, 0))\n",
    "            cv2.fillPoly(mask, [ptsZone2], (0, 255, 255))\n",
    "            cv2.fillPoly(mask, [ptsZone3], (0, 0, 255))\n",
    "\n",
    "            # Combine the mask with the original image using addWeighted to keep transparency\n",
    "            alpha = 0.4  # Transparency factor\n",
    "            frame = cv2.addWeighted(frame, 1, mask, alpha, 0)\n",
    "\n",
    "            center_x = (x1 + x2) / 2\n",
    "            center_y = (y1 + y2) / 2\n",
    "\n",
    "            # Define the corners of the bounding box\n",
    "            corners = [(x1, y1), (x1, y2), (x2, y1), (x2, y2)]\n",
    "\n",
    "            # Check if any corner of the bounding box is inside any zone\n",
    "            in_green = any(cv2.pointPolygonTest(ptsZone1, corner, False) >= 0 for corner in corners)\n",
    "            in_yellow = any(cv2.pointPolygonTest(ptsZone2, corner, False) >= 0 for corner in corners)\n",
    "            in_red = any(cv2.pointPolygonTest(ptsZone3, corner, False) >= 0 for corner in corners)\n",
    "\n",
    "            if in_red:\n",
    "                  putTextRect(frame,\"RED\", [380,100], scale=2.5, thickness=3, colorR=(0, 0, 240), offset=8, border=2, colorB=(0,0,0))\n",
    "            elif in_yellow:\n",
    "                  putTextRect(frame,\"YELLOW\", [190,100], scale=2.5, thickness=3, colorR=(0, 128, 255), offset=8, border=2, colorB=(0,0,0))\n",
    "            elif in_green:\n",
    "                  putTextRect(frame,\"GREEN\", [20,100], scale=2.5, thickness=3, colorR=(0, 220, 0), offset=8, border=2, colorB=(0,0,0))\n",
    "\n",
    "            # if cv2.pointPolygonTest(ptsZone1, (center_x, center_y), False) >= 0:\n",
    "            #     cv2.putText(frame, \"GREEN\", (20,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "            # elif cv2.pointPolygonTest(ptsZone2, (center_x, center_y), False) >= 0:\n",
    "            #     cv2.putText(frame, \"YELLOW\", (20,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "            # elif cv2.pointPolygonTest(ptsZone3, (center_x, center_y), False) >= 0:\n",
    "            #     cv2.putText(frame, \"RED\", (20,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    # if active_zone:\n",
    "    #          cv2.rectangle(frame, (0, int(H/7)), (W, int((3*H)/5)), (255, 0, 0), 4)\n",
    "    #          #cv2.putText(frame, \"Active Virtual Zone\", (int(W / 2) - 150, int(H / 2)), cv2.FONT_HERSHEY_COMPLEX, 1.3, (255, 0, 0), 3)\n",
    "    #          putTextRect(frame, f'{\"Active Virtual Zone\"}', [int(W / 2) - 170, int(3*H /5)+10],\n",
    "    #                     scale=2.5, thickness=2,colorR=(255,0,0))\n",
    "\n",
    "    # else:\n",
    "    #          cv2.rectangle(frame, (0, int(H/7)), (W, int((3*H)/5)), (0, 0, 255), 4)\n",
    "    #          #cv2.putText(frame, \"Inactive Virtual Zone\", (int(W / 2) - 150, int(H / 2)), cv2.FONT_HERSHEY_COMPLEX, 1.3, (0, 255, 255), 3)\n",
    "    #          putTextRect(frame, f'{\"Inactive Virtual Zone\"}', [int(W / 2) - 170, int(3*H /5)+10],\n",
    "    #                     scale=2.5, thickness=2,colorR=(0,0,255))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    detections = sv.Detections.from_ultralytics(results2)\n",
    "    #detections = detections.confidence > 0.5\n",
    "    detections = tracker.update_with_detections(detections)\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator(text_scale=0.5, text_thickness=2)\n",
    "\n",
    "\n",
    "\n",
    "    labels = [\n",
    "          #model2.model.names[class_id]\n",
    "          #for class_id\n",
    "          #in detections.class_id\n",
    "\n",
    "        f\"{tracker_id} {results2.names[class_id].upper()} {(confidence*100):.1f}%\"\n",
    "        for class_id, tracker_id, confidence\n",
    "        in zip(detections.class_id, detections.tracker_id, detections.confidence)\n",
    "      ]\n",
    "\n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "          scene=frame, detections=detections)\n",
    "    annotated_image = label_annotator.annotate(\n",
    "          scene=annotated_image, detections=detections, labels=labels)\n",
    "    annotated_image = trace_annotator.annotate(\n",
    "          scene=annotated_image, detections=detections)\n",
    "\n",
    "\n",
    "    # Write the frame to the output video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
